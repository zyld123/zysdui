{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zyld123/zysdui/blob/main/rwkv_role_playing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e4FYcjC0tos"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shengxia/RWKV_Role_Playing.git\n",
        "%cd RWKV_Role_Playing"
      ],
      "metadata": {
        "id": "KABj9I5300MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.13.1 --extra-index-url https://download.pytorch.org/whl/cu117 --upgrade\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "WwNa4xSc09dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -Lo model/RWKV-4-Raven-7B-v10x.pth  https://huggingface.co/wdmz/rwkv_mybackup/resolve/main/fp16i8_RWKV-4-Raven-7B-v10x-Eng49-Other1%25-20230423-ctx4096.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4daxu3L1Rbi",
        "outputId": "b1220e71-6ba2-47e0-f381-4804c584a3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1227  100  1227    0     0    222      0  0:00:05  0:00:05 --:--:--   287\n",
            "100 9947M  100 9947M    0     0  30.3M      0  0:05:28  0:05:28 --:--:-- 24.2M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python webui.py --model model/RWKV-4-Raven-7B-v10x.pth --cuda_on 1 --share --strategy 'cuda fp16i8 *20 -> cuda fp16'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmXmkvjx19_Z",
        "outputId": "894a2c71-d0e5-4687-c79b-b35739b7d414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using /root/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py39_cu117/wkv_cuda...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py39_cu117/wkv_cuda/build.ninja...\n",
            "Building extension module wkv_cuda...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=wkv_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.9/dist-packages/torch/include -isystem /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.9/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.9/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -t 4 -std=c++17 --use_fast_math -O3 --extra-device-vectorization -c /usr/local/lib/python3.9/dist-packages/rwkv/cuda/operators.cu -o operators.cuda.o \n",
            "[2/3] c++ -MMD -MF wrapper.o.d -DTORCH_EXTENSION_NAME=wkv_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.9/dist-packages/torch/include -isystem /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.9/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.9/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -c /usr/local/lib/python3.9/dist-packages/rwkv/cuda/wrapper.cpp -o wrapper.o \n",
            "[3/3] c++ wrapper.o operators.cuda.o -shared -L/usr/local/lib/python3.9/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o wkv_cuda.so\n",
            "Loading extension module wkv_cuda...\n",
            "RWKV_JIT_ON 1 RWKV_CUDA_ON 1 RESCALE_LAYER 6\n",
            "\n",
            "Loading model/RWKV-4-Raven-7B-v10x.pth ...\n",
            "Converted model: strategy cuda fp16i8 *20 -> cuda fp16, version 0.7\n",
            "\n",
            "Strategy: (total 32+1=33 layers)\n",
            "* cuda [float16, uint8], store 20 layers\n",
            "* cuda [float16, float16], store 13 layers\n",
            "0-cuda-float16-uint8 1-cuda-float16-uint8 2-cuda-float16-uint8 3-cuda-float16-uint8 4-cuda-float16-uint8 5-cuda-float16-uint8 6-cuda-float16-uint8 7-cuda-float16-uint8 8-cuda-float16-uint8 9-cuda-float16-uint8 10-cuda-float16-uint8 11-cuda-float16-uint8 12-cuda-float16-uint8 13-cuda-float16-uint8 14-cuda-float16-uint8 15-cuda-float16-uint8 16-cuda-float16-uint8 17-cuda-float16-uint8 18-cuda-float16-uint8 19-cuda-float16-uint8 20-cuda-float16-float16 21-cuda-float16-float16 22-cuda-float16-float16 23-cuda-float16-float16 24-cuda-float16-float16 25-cuda-float16-float16 26-cuda-float16-float16 27-cuda-float16-float16 28-cuda-float16-float16 29-cuda-float16-float16 30-cuda-float16-float16 31-cuda-float16-float16 32-cuda-float16-float16 \n",
            "emb.weight                        f16      cpu  50277  4096 \n",
            "blocks.0.ln1.weight               f16   cuda:0   4096       \n",
            "blocks.0.ln1.bias                 f16   cuda:0   4096       \n",
            "blocks.0.ln2.weight               f16   cuda:0   4096       \n",
            "blocks.0.ln2.bias                 f16   cuda:0   4096       \n",
            "blocks.0.att.time_decay           f32   cuda:0   4096       \n",
            "blocks.0.att.time_first           f32   cuda:0   4096       \n",
            "blocks.0.att.time_mix_k           f16   cuda:0   4096       \n",
            "blocks.0.att.time_mix_v           f16   cuda:0   4096       \n",
            "blocks.0.att.time_mix_r           f16   cuda:0   4096       \n",
            "blocks.0.att.key.weight            i8   cuda:0   4096  4096 \n",
            "blocks.0.att.value.weight          i8   cuda:0   4096  4096 \n",
            "blocks.0.att.receptance.weight     i8   cuda:0   4096  4096 \n",
            "blocks.0.att.output.weight         i8   cuda:0   4096  4096 \n",
            "blocks.0.ffn.time_mix_k           f16   cuda:0   4096       \n",
            "blocks.0.ffn.time_mix_r           f16   cuda:0   4096       \n",
            "blocks.0.ffn.key.weight            i8   cuda:0   4096 16384 \n",
            "blocks.0.ffn.receptance.weight     i8   cuda:0   4096  4096 \n",
            "blocks.0.ffn.value.weight          i8   cuda:0  16384  4096 \n",
            "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "blocks.31.ln1.weight              f16   cuda:0   4096       \n",
            "blocks.31.ln1.bias                f16   cuda:0   4096       \n",
            "blocks.31.ln2.weight              f16   cuda:0   4096       \n",
            "blocks.31.ln2.bias                f16   cuda:0   4096       \n",
            "blocks.31.att.time_decay          f32   cuda:0   4096       \n",
            "blocks.31.att.time_first          f32   cuda:0   4096       \n",
            "blocks.31.att.time_mix_k          f16   cuda:0   4096       \n",
            "blocks.31.att.time_mix_v          f16   cuda:0   4096       \n",
            "blocks.31.att.time_mix_r          f16   cuda:0   4096       \n",
            "blocks.31.att.key.weight          f16   cuda:0   4096  4096 \n",
            "blocks.31.att.value.weight        f16   cuda:0   4096  4096 \n",
            "blocks.31.att.receptance.weight   f16   cuda:0   4096  4096 \n",
            "blocks.31.att.output.weight       f16   cuda:0   4096  4096 \n",
            "blocks.31.ffn.time_mix_k          f16   cuda:0   4096       \n",
            "blocks.31.ffn.time_mix_r          f16   cuda:0   4096       \n",
            "blocks.31.ffn.key.weight          f16   cuda:0   4096 16384 \n",
            "blocks.31.ffn.receptance.weight   f16   cuda:0   4096  4096 \n",
            "blocks.31.ffn.value.weight        f16   cuda:0  16384  4096 \n",
            "ln_out.weight                     f16   cuda:0   4096       \n",
            "ln_out.bias                       f16   cuda:0   4096       \n",
            "head.weight                       f16   cuda:0   4096 50277 \n",
            "blocks.0.att.key.weight_mx        f16   cuda:0   4096       \n",
            "blocks.0.att.key.weight_my        f16   cuda:0   4096       \n",
            "blocks.0.att.key.weight_rx        f16   cuda:0   4096       \n",
            "blocks.0.att.key.weight_ry        f16   cuda:0   4096       \n",
            "blocks.0.att.value.weight_mx      f16   cuda:0   4096       \n",
            "blocks.0.att.value.weight_my      f16   cuda:0   4096       \n",
            "blocks.0.att.value.weight_rx      f16   cuda:0   4096       \n",
            "blocks.0.att.value.weight_ry      f16   cuda:0   4096       \n",
            "blocks.0.att.receptance.weight_mx  f16   cuda:0   4096       \n",
            "blocks.0.att.receptance.weight_my  f16   cuda:0   4096       \n",
            "blocks.0.att.receptance.weight_rx  f16   cuda:0   4096       \n",
            "blocks.0.att.receptance.weight_ry  f16   cuda:0   4096       \n",
            "blocks.0.att.output.weight_mx     f16   cuda:0   4096       \n",
            "blocks.0.att.output.weight_my     f16   cuda:0   4096       \n",
            "blocks.0.att.output.weight_rx     f16   cuda:0   4096       \n",
            "blocks.0.att.output.weight_ry     f16   cuda:0   4096       \n",
            "blocks.0.ffn.key.weight_mx        f16   cuda:0  16384       \n",
            "blocks.0.ffn.key.weight_my        f16   cuda:0   4096       \n",
            "blocks.0.ffn.key.weight_rx        f16   cuda:0  16384       \n",
            "blocks.0.ffn.key.weight_ry        f16   cuda:0   4096       \n",
            "blocks.0.ffn.receptance.weight_mx  f16   cuda:0   4096       \n",
            "blocks.0.ffn.receptance.weight_my  f16   cuda:0   4096       \n",
            "blocks.0.ffn.receptance.weight_rx  f16   cuda:0   4096       \n",
            "blocks.0.ffn.receptance.weight_ry  f16   cuda:0   4096       \n",
            "blocks.0.ffn.value.weight_my      f16   cuda:0  16384       \n",
            "blocks.0.ffn.value.weight_mx      f16   cuda:0   4096       \n",
            "blocks.0.ffn.value.weight_rx      f16   cuda:0   4096       \n",
            "blocks.0.ffn.value.weight_ry      f16   cuda:0  16384       \n",
            "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://d4df5dd90a5b08a76c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        }
      ]
    }
  ]
}