{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zyld123/zysdui/blob/testbranch/notebooks/comfyui_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
      ],
      "metadata": {
        "id": "aaaaaaaaaa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbbbbbbbbb"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd ComfyUI\n",
        "!pip install xformers -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download some models/checkpoints/vae or custom comfyui nodes (uncomment the commands for the ones you want)"
      ],
      "metadata": {
        "id": "cccccccccc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoints\n",
        "\n",
        "# SD1.5\n",
        "!wget -c https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Some SD1.5 anime style\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (anime style SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# VAE\n",
        "!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "\n",
        "# Loras\n",
        "#!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/t2i_adapter/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/t2i_adapter/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/t2i_adapter/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/t2i_adapter/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/t2i_adapter/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/t2i_adapter/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/t2i_adapter/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision model (needed for styles model)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_depth-fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_scribble-fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_openpose-fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "# ESRGAN upscale model\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dddddddddd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run ComfyUI with localtunnel (Recommended Way)\n",
        "\n",
        "use the **fp16** model configs for more speed\n",
        "\n"
      ],
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\")\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ],
      "metadata": {
        "id": "jjjjjjjjjjjjj",
        "outputId": "6a3f4e6a-a746-4036-b450-26a5cec7ae5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package in 1.277s\n",
            "\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[33m   ╭───────────────────────────────────────────────────────────────╮\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                               \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m      New \u001b[31mmajor\u001b[39m version of npm available! \u001b[31m6.14.8\u001b[39m → \u001b[32m9.6.2\u001b[39m       \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m   \u001b[33mChangelog:\u001b[39m \u001b[36mhttps://github.com/npm/cli/releases/tag/v9.6.2\u001b[39m   \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m               Run \u001b[32mnpm install -g npm\u001b[39m to update!               \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                               \u001b[33m│\u001b[39m\n",
            "\u001b[33m   ╰───────────────────────────────────────────────────────────────╯\u001b[39m\n",
            "\u001b[33m\u001b[39m\n",
            "Enabling highvram mode because your GPU has more vram than your computer has ram. If you don't want this use: --normalvram\n",
            "A matching Triton is not available, some optimizations will not be enabled.\n",
            "Error caught was: No module named 'triton'\n",
            "Set vram state to: HIGH VRAM\n",
            "Using xformers cross attention\n",
            "2023-03-17 05:18:11.350619: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-17 05:18:14.030778: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-17 05:18:14.030930: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-17 05:18:14.030951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\n",
            "ComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\n",
            "your url is: https://red-showers-build-35-237-193-116.loca.lt\n",
            "got prompt\n",
            "making attention of type 'vanilla-xformers' with 512 in_channels\n",
            "building MemoryEfficientAttnBlock with 512 in_channels...\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla-xformers' with 512 in_channels\n",
            "building MemoryEfficientAttnBlock with 512 in_channels...\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "100% 20/20 [00:10<00:00,  1.95it/s]\n",
            "got prompt\n",
            "Failed to validate prompt for output 9 Value not in list. LoraLoader, lora_name: epiNoiseoffset_v2.safetensors not in ['theovercomer8sContrastFix_sd15.safetensors', 'theovercomer8sContrastFix_sd21768.safetensors']\n",
            "output will be ignored\n",
            "invalid prompt: Prompt has no properly connected outputs\n",
            " Value not in list. LoraLoader, lora_name: epiNoiseoffset_v2.safetensors not in ['theovercomer8sContrastFix_sd15.safetensors', 'theovercomer8sContrastFix_sd21768.safetensors']\n",
            "got prompt\n",
            "Failed to validate prompt for output 9 Value not in list. LoraLoader, lora_name: epiNoiseoffset_v2.safetensors not in ['theovercomer8sContrastFix_sd15.safetensors', 'theovercomer8sContrastFix_sd21768.safetensors']\n",
            "output will be ignored\n",
            "invalid prompt: Prompt has no properly connected outputs\n",
            " Value not in list. LoraLoader, lora_name: epiNoiseoffset_v2.safetensors not in ['theovercomer8sContrastFix_sd15.safetensors', 'theovercomer8sContrastFix_sd21768.safetensors']\n",
            "got prompt\n",
            "Failed to validate prompt for output 9 Value not in list. LoraLoader, lora_name: epiNoiseoffset_v2.safetensors not in ['theovercomer8sContrastFix_sd15.safetensors', 'theovercomer8sContrastFix_sd21768.safetensors']\n",
            "output will be ignored\n",
            "invalid prompt: Prompt has no properly connected outputs\n",
            " Value not in list. LoraLoader, lora_name: epiNoiseoffset_v2.safetensors not in ['theovercomer8sContrastFix_sd15.safetensors', 'theovercomer8sContrastFix_sd21768.safetensors']\n",
            "got prompt\n",
            "Failed to validate prompt for output 9 Value not in list. LoraLoader, lora_name: epiNoiseoffset_v2.safetensors not in ['theovercomer8sContrastFix_sd15.safetensors', 'theovercomer8sContrastFix_sd21768.safetensors']\n",
            "output will be ignored\n",
            "invalid prompt: Prompt has no properly connected outputs\n",
            " Value not in list. LoraLoader, lora_name: epiNoiseoffset_v2.safetensors not in ['theovercomer8sContrastFix_sd15.safetensors', 'theovercomer8sContrastFix_sd21768.safetensors']\n",
            "got prompt\n",
            "making attention of type 'vanilla-xformers' with 512 in_channels\n",
            "building MemoryEfficientAttnBlock with 512 in_channels...\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla-xformers' with 512 in_channels\n",
            "building MemoryEfficientAttnBlock with 512 in_channels...\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "100% 20/20 [00:04<00:00,  4.77it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:04<00:00,  4.88it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:04<00:00,  4.91it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:04<00:00,  4.89it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:04<00:00,  4.96it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:04<00:00,  4.89it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:04<00:00,  4.62it/s]\n",
            "got prompt\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_v_proj.lora_up.weight\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in execute\n",
            "    executed += recursive_execute(self.server, prompt, self.outputs, x, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 54, in recursive_execute\n",
            "    executed += recursive_execute(server, prompt, outputs, input_unique_id, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 54, in recursive_execute\n",
            "    executed += recursive_execute(server, prompt, outputs, input_unique_id, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 54, in recursive_execute\n",
            "    executed += recursive_execute(server, prompt, outputs, input_unique_id, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 63, in recursive_execute\n",
            "    outputs[unique_id] = getattr(obj, obj.FUNCTION)(**input_data_all)\n",
            "  File \"/content/ComfyUI/nodes.py\", line 63, in encode\n",
            "    return ([[clip.encode(text), {}]], )\n",
            "  File \"/content/ComfyUI/comfy/sd.py\", line 360, in encode\n",
            "    raise e\n",
            "  File \"/content/ComfyUI/comfy/sd.py\", line 355, in encode\n",
            "    self.patcher.patch_model()\n",
            "  File \"/content/ComfyUI/comfy/sd.py\", line 282, in patch_model\n",
            "    weight += (alpha * torch.mm(mat1.flatten(start_dim=1).float(), mat2.flatten(start_dim=1).float())).reshape(weight.shape).type(weight.dtype).to(weight.device)\n",
            "RuntimeError: shape '[3072, 768]' is invalid for input of size 4194304\n",
            "\n",
            "got prompt\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_v_proj.lora_up.weight\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in execute\n",
            "    executed += recursive_execute(self.server, prompt, self.outputs, x, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 54, in recursive_execute\n",
            "    executed += recursive_execute(server, prompt, outputs, input_unique_id, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 54, in recursive_execute\n",
            "    executed += recursive_execute(server, prompt, outputs, input_unique_id, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 54, in recursive_execute\n",
            "    executed += recursive_execute(server, prompt, outputs, input_unique_id, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 63, in recursive_execute\n",
            "    outputs[unique_id] = getattr(obj, obj.FUNCTION)(**input_data_all)\n",
            "  File \"/content/ComfyUI/nodes.py\", line 63, in encode\n",
            "    return ([[clip.encode(text), {}]], )\n",
            "  File \"/content/ComfyUI/comfy/sd.py\", line 360, in encode\n",
            "    raise e\n",
            "  File \"/content/ComfyUI/comfy/sd.py\", line 355, in encode\n",
            "    self.patcher.patch_model()\n",
            "  File \"/content/ComfyUI/comfy/sd.py\", line 282, in patch_model\n",
            "    weight += (alpha * torch.mm(mat1.flatten(start_dim=1).float(), mat2.flatten(start_dim=1).float())).reshape(weight.shape).type(weight.dtype).to(weight.device)\n",
            "RuntimeError: shape '[3072, 768]' is invalid for input of size 4194304\n",
            "\n",
            "got prompt\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_12_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_13_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_14_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_15_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_16_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_17_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_18_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_19_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_20_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_21_self_attn_v_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc1.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc1.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc1.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc2.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc2.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_mlp_fc2.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_k_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_k_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_k_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_out_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_out_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_out_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_q_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_q_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_q_proj.lora_up.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_v_proj.alpha\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_v_proj.lora_down.weight\n",
            "lora key not loaded lora_te_text_model_encoder_layers_22_self_attn_v_proj.lora_up.weight\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in execute\n",
            "    executed += recursive_execute(self.server, prompt, self.outputs, x, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 54, in recursive_execute\n",
            "    executed += recursive_execute(server, prompt, outputs, input_unique_id, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 54, in recursive_execute\n",
            "    executed += recursive_execute(server, prompt, outputs, input_unique_id, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 54, in recursive_execute\n",
            "    executed += recursive_execute(server, prompt, outputs, input_unique_id, extra_data)\n",
            "  File \"/content/ComfyUI/execution.py\", line 63, in recursive_execute\n",
            "    outputs[unique_id] = getattr(obj, obj.FUNCTION)(**input_data_all)\n",
            "  File \"/content/ComfyUI/nodes.py\", line 63, in encode\n",
            "    return ([[clip.encode(text), {}]], )\n",
            "  File \"/content/ComfyUI/comfy/sd.py\", line 360, in encode\n",
            "    raise e\n",
            "  File \"/content/ComfyUI/comfy/sd.py\", line 355, in encode\n",
            "    self.patcher.patch_model()\n",
            "  File \"/content/ComfyUI/comfy/sd.py\", line 282, in patch_model\n",
            "    weight += (alpha * torch.mm(mat1.flatten(start_dim=1).float(), mat2.flatten(start_dim=1).float())).reshape(weight.shape).type(weight.dtype).to(weight.device)\n",
            "RuntimeError: shape '[3072, 768]' is invalid for input of size 4194304\n",
            "\n",
            "got prompt\n",
            "100% 10/10 [00:02<00:00,  4.88it/s]\n",
            "got prompt\n",
            "100% 10/10 [00:02<00:00,  4.73it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:04<00:00,  4.74it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:04<00:00,  4.87it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:03<00:00,  5.81it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:03<00:00,  5.84it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:03<00:00,  5.87it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:03<00:00,  5.80it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:03<00:00,  6.37it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:03<00:00,  6.41it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:03<00:00,  6.42it/s]\n",
            "got prompt\n",
            "100% 20/20 [00:03<00:00,  6.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run ComfyUI with colab iframe (use only in case the previous way with localtunnel doesn't work)\n",
        "use the **fp16** model configs for more speed\n",
        "\n",
        "You should see the ui appear in an iframe. If you get a 403 error, it's your firefox settings or an extension that's messing things up.\n",
        "\n",
        "If you want to open it in another window use the link.\n",
        "\n",
        "Note that some UI features like live image previews won't work because the colab iframe blocks websockets."
      ],
      "metadata": {
        "id": "gggggggggg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import socket\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  from google.colab import output\n",
        "  output.serve_kernel_port_as_iframe(port, height=1024)\n",
        "  print(\"to open it in a window you can open this link here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ],
      "metadata": {
        "id": "hhhhhhhhhh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}